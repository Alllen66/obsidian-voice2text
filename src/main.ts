import { App, Plugin, PluginSettingTab, Setting, Notice, requestUrl } from 'obsidian';
import { RecordingModal } from './components/RecordingModal';
import { AudioRecorder } from './components/AudioRecorder';

interface Voice2TextSettings {
  apiKey: string;
  saveAudio: boolean;
}

const DEFAULT_SETTINGS: Voice2TextSettings = {
  apiKey: '',
  saveAudio: true
};

export default class Voice2TextPlugin extends Plugin {
  settings: Voice2TextSettings;
  audioRecorder: AudioRecorder;
  recordingModal: RecordingModal | null = null;
  private statusBarItem: HTMLElement;

  async onload() {
    await this.loadSettings();
    this.audioRecorder = new AudioRecorder();

    // æ·»åŠ è®¾ç½®é€‰é¡¹å¡
    this.addSettingTab(new Voice2TextSettingTab(this.app, this));

    // æ·»åŠ å‘½ä»¤
    this.addCommand({
      id: 'start-recording',
      name: 'å¼€å§‹å½•éŸ³',
      callback: () => this.startRecording()
    });

    // æ·»åŠ çŠ¶æ€æ é¡¹
    this.createStatusBarItem();
    this.statusBarItem.addClass('mod-clickable');
    this.statusBarItem.setAttribute('aria-label', 'å¼€å§‹å½•éŸ³');
    this.statusBarItem.setAttribute('title', 'ç‚¹å‡»å¼€å§‹å½•éŸ³');
    this.statusBarItem.addEventListener('click', () => {
      this.startRecording();
    });
  }

  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }

  async saveSettings() {
    await this.saveData(this.settings);
  }

  async startRecording() {
    try {
      await this.audioRecorder.startRecording();
      const stream = this.audioRecorder.getStream();
      
      if (!stream) {
        throw new Error('æ— æ³•è·å–éŸ³é¢‘æµ');
      }

      // åˆ›å»ºå¹¶æ˜¾ç¤ºå½•éŸ³å¼¹çª—
      this.recordingModal = new RecordingModal(
        this.app,
        async (cancelled) => {
          if (!cancelled) {
            await this.stopRecording();
          } else {
            this.audioRecorder.cleanup();
          }
          this.recordingModal = null;
        },
        () => this.audioRecorder.pauseRecording(),
        () => this.audioRecorder.resumeRecording(),
        stream
      );
      
      this.recordingModal.open();
    } catch (error) {
      new Notice('å½•éŸ³å¤±è´¥: ' + error.message);
    }
  }

  async stopRecording() {
    try {
      const audioBlob = await this.audioRecorder.stopRecording();
      
      // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
      if (this.settings.saveAudio) {
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const fileName = `å½•éŸ³_${timestamp}.wav`;
        const file = new File([audioBlob], fileName, { type: 'audio/wav' });
        await this.app.vault.createBinary(fileName, await file.arrayBuffer());
      }

      // æ˜¾ç¤ºè½¬å†™çŠ¶æ€
      if (this.recordingModal) {
        this.recordingModal.showTranscribing();
      }

      // è½¬å†™éŸ³é¢‘
      const transcription = await this.transcribeAudio(audioBlob);
      
      // æ›´æ–°è½¬å†™æ–‡æœ¬
      if (this.recordingModal) {
        this.recordingModal.hideTranscribing();
        this.recordingModal.setTranscriptionText(transcription);
      }
    } catch (error) {
      new Notice('å¤„ç†å½•éŸ³å¤±è´¥: ' + error.message);
    }
  }

  private async transcribeAudio(audioBlob: Blob): Promise<string> {
    try {
      // å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º base64
      const reader = new FileReader();
      const base64Audio = await new Promise<string>((resolve) => {
        reader.onload = () => resolve(reader.result as string);
        reader.readAsDataURL(audioBlob);
      });

      // åˆ›å»ºè¯·æ±‚ä½“
      const requestBody = {
        file: base64Audio,
        model: 'whisper-1',
        language: 'zh'
      };

      const response = await requestUrl({
        url: 'https://api.openai.com/v1/audio/transcriptions',
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.settings.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
      });

      if (response.status !== 200) {
        throw new Error(`è½¬å†™å¤±è´¥: ${response.status} ${response.text}`);
      }

      const data = JSON.parse(response.text);
      return data.text;
    } catch (error) {
      console.error('è½¬å†™é”™è¯¯:', error);
      throw error;
    }
  }

  private createStatusBarItem(): void {
    this.statusBarItem = this.addStatusBarItem();
    const icon = document.createElement('span');
    icon.setText('ğŸ™');
    this.statusBarItem.appendChild(icon);
  }

  private updateStatusBarIcon(isRecording: boolean): void {
    if (!this.statusBarItem) return;
    
    // æ¸…é™¤ç°æœ‰å†…å®¹
    while (this.statusBarItem.firstChild) {
      this.statusBarItem.removeChild(this.statusBarItem.firstChild);
    }
    
    const icon = document.createElement('span');
    icon.setText(isRecording ? 'â¹' : 'ğŸ™');
    this.statusBarItem.appendChild(icon);
  }
}

class Voice2TextSettingTab extends PluginSettingTab {
  constructor(app: App, plugin: Voice2TextPlugin) {
    super(app, plugin);
    this.plugin = plugin;
  }

  plugin: Voice2TextPlugin;

  display(): void {
    const { containerEl } = this;
    containerEl.empty();

    containerEl.createEl('h2', { text: 'è¯­éŸ³è½¬æ–‡å­—è®¾ç½®' });

    new Setting(containerEl)
      .setName('OpenAI API Key')
      .setDesc('è¯·è¾“å…¥ä½ çš„ OpenAI API Key')
      .addText(text => text
        .setPlaceholder('è¾“å…¥ API Key')
        .setValue(this.plugin.settings.apiKey)
        .onChange(async (value) => {
          this.plugin.settings.apiKey = value;
          await this.plugin.saveSettings();
        }));

    new Setting(containerEl)
      .setName('ä¿å­˜éŸ³é¢‘æ–‡ä»¶')
      .setDesc('æ˜¯å¦ä¿å­˜å½•éŸ³æ–‡ä»¶åˆ°æ–‡æ¡£åº“')
      .addToggle(toggle => toggle
        .setValue(this.plugin.settings.saveAudio)
        .onChange(async (value) => {
          this.plugin.settings.saveAudio = value;
          await this.plugin.saveSettings();
        }));
  }
} 